
RUNNING 5000 EPISODES

BEGINNING EPISODE: 1

Current Policy Convergence Ratio: 0.545455
Step: 0, S: (4, 4), A: south, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.409091
Step: 1, S: (4, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.409091
Step: 2, S: (4, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 3, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 4, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.363636
Step: 5, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 6, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 7, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 8, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.409091
Step: 9, S: (4, 4), A: north, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 10, S: (4, 4), A: east, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 11, S: (4, 4), A: north, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 12, S: (4, 4), A: north, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 13, S: (4, 4), A: south, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.409091
Step: 14, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 15, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.545455
--------------------------------
EPISODE 1 COMPLETE: RETURN WAS 2.05891132095

TOTAL STEPS: 16, EPISODE STEPS: 16
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 0.0, ((0, 2), 'south'): 0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0, ((4, 2), 'exit'): 5.0, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0, ((3, 3), 'north'): 0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0, ((0, 3), 'west'): 0, ((2, 4), 'south'): 0, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0, ((4, 3), 'west'): 0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0, ((1, 4), 'west'): 0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0, ((1, 4), 'south'): 0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0, ((3, 1), 'east'): 0, ((4, 1), 'east'): 0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0.0}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:west
State:(0, 2), optimal:south, current:east
State:(0, 3), optimal:south, current:east
State:(0, 4), optimal:east, current:north
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:south
State:(1, 4), optimal:east, current:west
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:south
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:north
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:west
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:north
State:(4, 4), optimal:south, current:west
################################
Current Policy Convergence Ratio: 0.409091
################################

BEGINNING EPISODE: 2

Current Policy Convergence Ratio: 0.500000
Step: 0, S: (2, 3), A: west, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 1, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 2, S: (3, 3), A: north, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 3, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 4, S: (4, 4), A: south, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 5, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 6, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.409091
Step: 7, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 8, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 9, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 10, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 11, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Convergence Ratio: 0.363636
Step: 12, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Convergence Ratio: 0.500000
--------------------------------
EPISODE 2 COMPLETE: RETURN WAS 0.282429536481

TOTAL STEPS: 29, EPISODE STEPS: 13
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 0.0, ((0, 2), 'south'): 0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0, ((4, 2), 'exit'): 5.0, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.5, ((0, 3), 'west'): 0, ((2, 4), 'south'): 0, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0, ((4, 3), 'west'): 0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0, ((1, 4), 'west'): 0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0, ((3, 1), 'east'): 0, ((4, 1), 'east'): 0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0.0}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:east
State:(0, 2), optimal:south, current:east
State:(0, 3), optimal:north, current:west
State:(0, 4), optimal:east, current:west
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:north
State:(1, 4), optimal:east, current:west
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:east
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:north
State:(2, 4), optimal:south, current:east
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:west
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:north
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:east
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.545455
################################

BEGINNING EPISODE: 3

Current Policy Convergence Ratio: 0.590909
Step: 0, S: (3, 3), A: north, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 1, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.363636
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 3, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 4, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 5, S: (4, 3), A: west, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 6, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 7, S: (4, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 8, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 9, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.500000
--------------------------------
EPISODE 3 COMPLETE: RETURN WAS 3.87420489

TOTAL STEPS: 39, EPISODE STEPS: 10
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 0.0, ((0, 2), 'south'): 0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0, ((4, 2), 'exit'): 7.5, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.5, ((0, 3), 'west'): 0, ((2, 4), 'south'): 0, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0, ((1, 4), 'west'): 0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0, ((3, 1), 'east'): 0, ((4, 1), 'east'): 0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 2.25}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:south
State:(0, 2), optimal:south, current:east
State:(0, 3), optimal:south, current:south
State:(0, 4), optimal:east, current:south
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:north
State:(1, 4), optimal:east, current:west
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:east
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:west
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:west
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:west
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.545455
################################

BEGINNING EPISODE: 4

Current Policy Convergence Ratio: 0.454545
Step: 0, S: (2, 3), A: west, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 1, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Convergence Ratio: 0.409091
Step: 2, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Convergence Ratio: 0.454545
--------------------------------
EPISODE 4 COMPLETE: RETURN WAS 0.81

TOTAL STEPS: 42, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 0.0, ((0, 2), 'south'): 0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0, ((4, 2), 'exit'): 7.5, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.75, ((0, 3), 'west'): 0, ((2, 4), 'south'): 0, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.225, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0, ((1, 4), 'west'): 0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0, ((3, 1), 'east'): 0, ((4, 1), 'east'): 0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 2.25}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:west
State:(0, 2), optimal:south, current:east
State:(0, 3), optimal:north, current:south
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:west
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:west
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:south
State:(3, 3), optimal:east, current:south
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:east
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.590909
################################

BEGINNING EPISODE: 5

Current Policy Convergence Ratio: 0.409091
Step: 0, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 1, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 2, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 3, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 4, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 5, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 6, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 7, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 8, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 9, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 10, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 11, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Convergence Ratio: 0.681818
--------------------------------
EPISODE 5 COMPLETE: RETURN WAS 0.31381059609

TOTAL STEPS: 54, EPISODE STEPS: 12
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 0.0, ((0, 2), 'south'): 0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0, ((4, 2), 'exit'): 7.5, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.875, ((0, 3), 'west'): 0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.10125, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.45, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0, ((3, 1), 'east'): 0, ((4, 1), 'east'): 0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 2.25}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:east
State:(0, 2), optimal:south, current:east
State:(0, 3), optimal:south, current:east
State:(0, 4), optimal:east, current:west
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:west
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:south
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:west
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:south
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:north
################################
Current Policy Convergence Ratio: 0.545455
################################

BEGINNING EPISODE: 6

Current Policy Convergence Ratio: 0.681818
Step: 0, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 1, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 2, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 3, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 4, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 5, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 6, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 7, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 8, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 9, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 10, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 11, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 12, S: (0, 3), A: south, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 13, S: (0, 2), A: east, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 14, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 15, S: (0, 1), A: south, S': (0, 0), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 16, S: (0, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Convergence Ratio: 0.636364
--------------------------------
EPISODE 6 COMPLETE: RETURN WAS -1.85302018885

TOTAL STEPS: 71, EPISODE STEPS: 17
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 0.0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 7.5, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.875, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.10125, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.45, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0, ((4, 1), 'east'): 0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 2.25}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:south
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:north, current:west
State:(0, 4), optimal:east, current:north
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:north
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:west
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:west
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:north
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:south
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:north
################################
Current Policy Convergence Ratio: 0.454545
################################

BEGINNING EPISODE: 7

Current Policy Convergence Ratio: 0.636364
Step: 0, S: (3, 1), A: north, S': (3, 1), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 1, S: (3, 1), A: north, S': (3, 1), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 2, S: (3, 1), A: west, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 3, S: (2, 1), A: west, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 4, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 5, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 6, S: (2, 1), A: east, S': (3, 1), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 7, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 8, S: (4, 1), A: east, S': (4, 1), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 9, S: (4, 1), A: west, S': (3, 1), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 10, S: (3, 1), A: south, S': (3, 0), R: 0.0

Current Policy Convergence Ratio: 0.409091
Step: 11, S: (3, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Convergence Ratio: 0.500000
--------------------------------
EPISODE 7 COMPLETE: RETURN WAS -3.1381059609

TOTAL STEPS: 83, EPISODE STEPS: 12
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 0.0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 7.5, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.875, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.10125, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.45, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 2.25}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:east
State:(0, 2), optimal:south, current:east
State:(0, 3), optimal:north, current:north
State:(0, 4), optimal:east, current:west
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:north
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:west
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:south
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:north
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:west
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:west
################################
Current Policy Convergence Ratio: 0.545455
################################

BEGINNING EPISODE: 8

Current Policy Convergence Ratio: 0.545455
Step: 0, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 1, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 2, S: (3, 3), A: north, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 3, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 4, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 5, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 6, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 7, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Convergence Ratio: 0.545455
--------------------------------
EPISODE 8 COMPLETE: RETURN WAS 0.4782969

TOTAL STEPS: 91, EPISODE STEPS: 8
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 0.0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 7.5, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.06834375000000001, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 2.25}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:south
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:north, current:south
State:(0, 4), optimal:east, current:north
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:south
State:(1, 4), optimal:east, current:west
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:south
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.545455
################################

BEGINNING EPISODE: 9

Current Policy Convergence Ratio: 0.545455
Step: 0, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 1, S: (4, 4), A: east, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.454545
Step: 2, S: (4, 4), A: east, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 3, S: (4, 4), A: south, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 4, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.500000
Step: 5, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.590909
--------------------------------
EPISODE 9 COMPLETE: RETURN WAS 5.9049

TOTAL STEPS: 97, EPISODE STEPS: 6
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 1.0125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 8.75, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.06834375000000001, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 4.5}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:south
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:south, current:south
State:(0, 4), optimal:east, current:south
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:south
State:(1, 4), optimal:east, current:south
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:east
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:east
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.636364
################################

BEGINNING EPISODE: 10

Current Policy Convergence Ratio: 0.636364
Step: 0, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Convergence Ratio: 0.545455
Step: 1, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.727273
--------------------------------
EPISODE 10 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 100, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 1.0125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.375, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): 0, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 3.9375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.06834375000000001, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 4.5}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:south
State:(0, 2), optimal:south, current:south
State:(0, 3), optimal:south, current:north
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:west
State:(1, 4), optimal:east, current:west
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:east
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:north
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.681818
################################

BEGINNING EPISODE: 11

Current Policy Convergence Ratio: 0.590909
Step: 0, S: (2, 1), A: west, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 1, S: (1, 1), A: south, S': (1, 0), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 2, S: (1, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Convergence Ratio: 0.727273
--------------------------------
EPISODE 11 COMPLETE: RETURN WAS -8.1

TOTAL STEPS: 103, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 1.0125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.375, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.0, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0.0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 3.9375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.06834375000000001, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 4.5}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:west
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:south, current:north
State:(0, 4), optimal:east, current:west
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:north
State:(1, 4), optimal:east, current:south
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:west
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:west
State:(3, 3), optimal:east, current:west
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.545455
################################

BEGINNING EPISODE: 12

Current Policy Convergence Ratio: 0.590909
Step: 0, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 1, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 2, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 3, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 4, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 5, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 6, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.590909
Step: 7, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 8, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 9, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 10, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 11, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 12, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 13, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 14, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 15, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 16, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.727273
--------------------------------
EPISODE 12 COMPLETE: RETURN WAS 1.85302018885

TOTAL STEPS: 120, EPISODE STEPS: 17
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 1.0125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.6875, ((2, 4), 'east'): 0.030754687500000006, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.020503125000000004, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.0, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0.0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 2.025, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.06834375000000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 3.9375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.14807812500000003, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 6.46875}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:east
State:(0, 2), optimal:south, current:south
State:(0, 3), optimal:north, current:east
State:(0, 4), optimal:east, current:west
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:north
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:east
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:west
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.772727
################################

BEGINNING EPISODE: 13

Current Policy Convergence Ratio: 0.681818
Step: 0, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 1, S: (4, 4), A: south, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 2, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 3, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.636364
--------------------------------
EPISODE 13 COMPLETE: RETURN WAS 7.29

TOTAL STEPS: 124, EPISODE STEPS: 4
Learned QValue: {((0, 1), 'east'): 0, ((4, 4), 'south'): 3.4171875000000003, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.84375, ((2, 4), 'east'): 0.030754687500000006, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.020503125000000004, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.0, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0.0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 2.025, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.06834375000000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 3.9375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.14807812500000003, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 7.59375}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:east
State:(0, 2), optimal:south, current:east
State:(0, 3), optimal:south, current:west
State:(0, 4), optimal:east, current:south
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:west
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:north
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:east
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.636364
################################

BEGINNING EPISODE: 14

Current Policy Convergence Ratio: 0.636364
Step: 0, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 1, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 2, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 3, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 4, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 5, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 6, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 7, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 8, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 9, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 10, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 11, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 12, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 13, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 14, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 15, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 16, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.636364
Step: 17, S: (0, 3), A: south, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 18, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 19, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 20, S: (1, 1), A: south, S': (1, 0), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 21, S: (1, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Convergence Ratio: 0.681818
--------------------------------
EPISODE 14 COMPLETE: RETURN WAS -1.09418989132

TOTAL STEPS: 146, EPISODE STEPS: 22
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 3.4171875000000003, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.84375, ((2, 4), 'east'): 0.030754687500000006, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.020503125000000004, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0, ((3, 3), 'east'): 2.025, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.06834375000000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 3.9375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.013839609375000003, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.14807812500000003, ((1, 4), 'south'): 0.030754687500000006, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.030754687500000006, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 7.59375}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:south
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:north, current:west
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:east
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:east
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.727273
################################

BEGINNING EPISODE: 15

Current Policy Convergence Ratio: 0.636364
Step: 0, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 1, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.727273
--------------------------------
EPISODE 15 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 149, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 3.4171875000000003, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.921875, ((2, 4), 'east'): 0.030754687500000006, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.020503125000000004, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0, ((3, 3), 'east'): 2.025, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.06834375000000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 6.3984375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.013839609375000003, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.14807812500000003, ((1, 4), 'south'): 0.030754687500000006, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 1.771875, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.030754687500000006, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 7.59375}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:north
State:(0, 2), optimal:south, current:west
State:(0, 3), optimal:south, current:east
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:east
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:east
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.727273
################################

BEGINNING EPISODE: 16

Current Policy Convergence Ratio: 0.681818
Step: 0, S: (4, 4), A: south, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 1, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.863636
--------------------------------
EPISODE 16 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 152, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.9609375, ((2, 4), 'east'): 0.030754687500000006, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.020503125000000004, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0, ((3, 3), 'east'): 2.025, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.06834375000000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 6.3984375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.013839609375000003, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.14807812500000003, ((1, 4), 'south'): 0.030754687500000006, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 1.771875, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.030754687500000006, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 8.26171875}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:north
State:(0, 2), optimal:south, current:south
State:(0, 3), optimal:north, current:south
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:north
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:west
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:east
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.727273
################################

BEGINNING EPISODE: 17

Current Policy Convergence Ratio: 0.727273
Step: 0, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 1, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 2, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 3, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 4, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 5, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 6, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 7, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 8, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 9, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 10, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 11, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 12, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 13, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.772727
--------------------------------
EPISODE 17 COMPLETE: RETURN WAS 2.54186582833

TOTAL STEPS: 166, EPISODE STEPS: 14
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.98046875, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9375, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0, ((3, 3), 'east'): 4.7302734375, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.07973437500000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 6.3984375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.020759414062500002, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 1.771875, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.04613203125000001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 8.61328125}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:west
State:(0, 2), optimal:south, current:west
State:(0, 3), optimal:north, current:north
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:west
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:west
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:east
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.727273
################################

BEGINNING EPISODE: 18

Current Policy Convergence Ratio: 0.772727
Step: 0, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 1, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 2, S: (2, 1), A: west, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 3, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 4, S: (2, 1), A: west, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 5, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 6, S: (2, 1), A: west, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 7, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.863636
Step: 8, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 9, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Convergence Ratio: 0.727273
--------------------------------
EPISODE 18 COMPLETE: RETURN WAS 0.387420489

TOTAL STEPS: 176, EPISODE STEPS: 10
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.98046875, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0, ((3, 3), 'east'): 4.7302734375, ((0, 0), 'exit'): -5.0, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.07973437500000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 6.3984375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.020759414062500002, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 1.771875, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.04613203125000001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.61328125}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:south
State:(0, 2), optimal:south, current:east
State:(0, 3), optimal:north, current:north
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:west
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:east
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.727273
################################

BEGINNING EPISODE: 19

Current Policy Convergence Ratio: 0.681818
Step: 0, S: (0, 1), A: west, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 1, S: (0, 1), A: south, S': (0, 0), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 2, S: (0, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Convergence Ratio: 0.681818
--------------------------------
EPISODE 19 COMPLETE: RETURN WAS -8.1

TOTAL STEPS: 179, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.98046875, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): -2.25, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0, ((3, 3), 'east'): 4.7302734375, ((0, 0), 'exit'): -7.5, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.07973437500000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 6.3984375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.020759414062500002, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 1.771875, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 0.04613203125000001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.61328125}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:north
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:south, current:west
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:west
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:east
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.681818
################################

BEGINNING EPISODE: 20

Current Policy Convergence Ratio: 0.681818
Step: 0, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 1, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 2, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 3, S: (1, 1), A: west, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 4, S: (0, 1), A: west, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 5, S: (0, 1), A: south, S': (0, 0), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 6, S: (0, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Convergence Ratio: 0.727273
--------------------------------
EPISODE 20 COMPLETE: RETURN WAS -5.31441

TOTAL STEPS: 186, EPISODE STEPS: 7
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.98046875, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): -4.5, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.10125, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 4.7302734375, ((0, 0), 'exit'): -8.75, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.07973437500000001, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 6.3984375, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.020503125000000004, ((1, 4), 'west'): 0.020759414062500002, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 1.771875, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 0.04613203125000001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.61328125}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:west
State:(0, 2), optimal:south, current:south
State:(0, 3), optimal:north, current:west
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:east
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:south
State:(2, 4), optimal:south, current:east
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.772727
################################

BEGINNING EPISODE: 21

Current Policy Convergence Ratio: 0.727273
Step: 0, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 1, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 2, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 3, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 4, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 5, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 6, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 7, S: (0, 3), A: south, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 8, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 9, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 10, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 11, S: (1, 1), A: west, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 12, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 13, S: (0, 2), A: east, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 14, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 15, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 16, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 17, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 18, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 19, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 20, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 21, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 22, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 23, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 24, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 25, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 26, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 27, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 28, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 29, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Convergence Ratio: 0.681818
Step: 30, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Convergence Ratio: 0.727273
Step: 31, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 32, S: (2, 3), A: west, S': (2, 3), R: 0.0

Current Policy Convergence Ratio: 0.772727
Step: 33, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 34, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.863636
Step: 35, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.863636
Step: 36, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.818182
--------------------------------
EPISODE 21 COMPLETE: RETURN WAS 0.225283995449

TOTAL STEPS: 223, EPISODE STEPS: 37
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.2784375, ((0, 3), 'north'): 0.03632897460937501, ((4, 2), 'exit'): 9.990234375, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): -4.5, ((2, 3), 'east'): 2.128623046875, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.009341736328125003, ((2, 4), 'south'): 0.32906250000000004, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0.009341736328125003, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.02218662377929688, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0991838671875, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 6.24111328125, ((0, 0), 'exit'): -8.75, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.1390510546875, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 6.3984375, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.04613203125000001, ((1, 4), 'west'): 0.031139121093750007, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.03892390136718751, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.018683472656250005, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 1.771875, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 0.05894648437500001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.7978515625}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:north
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:north, current:north
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:north
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:east
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.818182
################################

BEGINNING EPISODE: 22

Current Policy Convergence Ratio: 0.818182
Step: 0, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 1, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.863636
--------------------------------
EPISODE 22 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 226, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.2784375, ((0, 3), 'north'): 0.03632897460937501, ((4, 2), 'exit'): 9.9951171875, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): -4.5, ((2, 3), 'east'): 2.128623046875, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.009341736328125003, ((2, 4), 'south'): 0.32906250000000004, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0.009341736328125003, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.02218662377929688, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0991838671875, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 6.24111328125, ((0, 0), 'exit'): -8.75, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.1390510546875, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 7.69482421875, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.04613203125000001, ((1, 4), 'west'): 0.031139121093750007, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.03892390136718751, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.018683472656250005, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 3.7652343750000004, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 0.05894648437500001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.7978515625}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:west
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:north, current:north
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:east
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:east
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.863636
################################

BEGINNING EPISODE: 23

Current Policy Convergence Ratio: 0.818182
Step: 0, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Convergence Ratio: 0.863636
Step: 1, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.818182
--------------------------------
EPISODE 23 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 229, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0.0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.2784375, ((0, 3), 'north'): 0.03632897460937501, ((4, 2), 'exit'): 9.99755859375, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): -4.5, ((2, 3), 'east'): 2.128623046875, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.009341736328125003, ((2, 4), 'south'): 0.32906250000000004, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0.009341736328125003, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.02218662377929688, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0991838671875, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.07958984375, ((0, 0), 'exit'): -8.75, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.1390510546875, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 7.69482421875, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.04613203125000001, ((1, 4), 'west'): 0.031139121093750007, ((1, 1), 'east'): 0.0, ((0, 4), 'north'): 0.03892390136718751, ((2, 1), 'west'): 0.0, ((0, 4), 'south'): 0.018683472656250005, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 3.7652343750000004, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 0.05894648437500001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.896728515625}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:north
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:north, current:north
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:west
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:north
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:east
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.818182
################################

BEGINNING EPISODE: 24

Current Policy Convergence Ratio: 0.818182
Step: 0, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.863636
Step: 1, S: (2, 1), A: west, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.863636
Step: 2, S: (1, 1), A: west, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 3, S: (0, 1), A: west, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.818182
Step: 4, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.863636
Step: 5, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.909091
Step: 6, S: (2, 1), A: east, S': (3, 1), R: 0.0

Current Policy Convergence Ratio: 0.909091
Step: 7, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Convergence Ratio: 0.909091
Step: 8, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 9, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.909091
--------------------------------
EPISODE 24 COMPLETE: RETURN WAS 3.87420489

TOTAL STEPS: 239, EPISODE STEPS: 10
Learned QValue: {((0, 1), 'east'): 0.0854296875, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 1.6943554687500002, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.2784375, ((0, 3), 'north'): 0.03632897460937501, ((4, 2), 'exit'): 9.998779296875, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): -4.5, ((2, 3), 'east'): 2.128623046875, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.009341736328125003, ((2, 4), 'south'): 0.32906250000000004, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0.009341736328125003, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.02218662377929688, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0991838671875, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.07958984375, ((0, 0), 'exit'): -8.75, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.1390510546875, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 8.3463134765625, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.04613203125000001, ((1, 4), 'west'): 0.031139121093750007, ((1, 1), 'east'): 0.284765625, ((0, 4), 'north'): 0.03892390136718751, ((2, 1), 'west'): 0.0854296875, ((0, 4), 'south'): 0.018683472656250005, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 5.345288085937501, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 0.05894648437500001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.896728515625}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:east
State:(0, 2), optimal:south, current:north
State:(0, 3), optimal:south, current:north
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:east
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:east
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:east
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 0.909091
################################

BEGINNING EPISODE: 25

Current Policy Convergence Ratio: 0.909091
Step: 0, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.909091
Step: 1, S: (0, 2), A: east, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 2, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 3, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 1.000000
Step: 4, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 5, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 6, S: (2, 1), A: west, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 7, S: (1, 1), A: west, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 1.000000
Step: 8, S: (0, 1), A: west, S': (0, 1), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 9, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 10, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 11, S: (2, 1), A: east, S': (3, 1), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 12, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 13, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Convergence Ratio: 0.954545
Step: 14, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Convergence Ratio: 0.954545
--------------------------------
EPISODE 25 COMPLETE: RETURN WAS 2.2876792455

TOTAL STEPS: 254, EPISODE STEPS: 15
Learned QValue: {((0, 1), 'east'): 0.4926089355468751, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.038443359375, ((0, 2), 'west'): 0.006305672021484377, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 3.2525573730468755, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.2784375, ((0, 3), 'north'): 0.03632897460937501, ((4, 2), 'exit'): 9.9993896484375, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): -4.5, ((2, 3), 'east'): 2.128623046875, ((0, 2), 'east'): 0.004203781347656251, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.009341736328125003, ((2, 4), 'south'): 0.32906250000000004, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0.009341736328125003, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.02218662377929688, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0991838671875, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0.07688671875000001, ((3, 3), 'east'): 7.07958984375, ((0, 0), 'exit'): -8.75, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.1390510546875, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 8.672607421875, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.04613203125000001, ((1, 4), 'west'): 0.031139121093750007, ((1, 1), 'east'): 1.21488134765625, ((0, 4), 'north'): 0.03892390136718751, ((2, 1), 'west'): 0.4498940917968751, ((0, 4), 'south'): 0.018683472656250005, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 6.428485107421876, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.07688671875000001, ((0, 4), 'east'): 0.05894648437500001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.896728515625}

--------------------------------

State:(0, 0), optimal:exit, current:exit
State:(0, 1), optimal:east, current:east
State:(0, 2), optimal:south, current:south
State:(0, 3), optimal:north, current:north
State:(0, 4), optimal:east, current:east
State:(1, 0), optimal:exit, current:exit
State:(1, 1), optimal:east, current:east
State:(1, 4), optimal:east, current:east
State:(2, 0), optimal:exit, current:exit
State:(2, 1), optimal:east, current:east
State:(2, 2), optimal:exit, current:exit
State:(2, 3), optimal:east, current:east
State:(2, 4), optimal:south, current:south
State:(3, 0), optimal:exit, current:exit
State:(3, 1), optimal:east, current:east
State:(3, 3), optimal:east, current:east
State:(3, 4), optimal:south, current:south
State:(4, 0), optimal:exit, current:exit
State:(4, 1), optimal:north, current:north
State:(4, 2), optimal:exit, current:exit
State:(4, 3), optimal:south, current:south
State:(4, 4), optimal:south, current:south
################################
Current Policy Convergence Ratio: 1.000000
################################

##################################
The policy has converged

TOTAL STEPS: 254, EPISODE STEPS: 15
##################################
Learned QValue: {((0, 1), 'east'): 0.4926089355468751, ((4, 4), 'south'): 5.12578125, ((0, 2), 'south'): 0.038443359375, ((0, 2), 'west'): 0.006305672021484377, ((3, 1), 'west'): 0.0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 3.2525573730468755, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0.2784375, ((0, 3), 'north'): 0.03632897460937501, ((4, 2), 'exit'): 9.9993896484375, ((2, 4), 'east'): 0.22040859375, ((0, 1), 'south'): -4.5, ((2, 3), 'east'): 2.128623046875, ((0, 2), 'east'): 0.004203781347656251, ((3, 3), 'south'): 0.06834375000000001, ((3, 3), 'north'): 0.020503125000000004, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.96875, ((0, 3), 'west'): 0.009341736328125003, ((2, 4), 'south'): 0.32906250000000004, ((4, 4), 'east'): 0.0, ((3, 4), 'east'): 0.455625, ((1, 4), 'north'): 0.04100625000000001, ((0, 2), 'north'): 0.009341736328125003, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0.25312500000000004, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.02218662377929688, ((1, 0), 'exit'): -7.5, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0991838671875, ((1, 1), 'south'): -2.25, ((1, 1), 'west'): 0.07688671875000001, ((3, 3), 'east'): 7.07958984375, ((0, 0), 'exit'): -8.75, ((2, 3), 'south'): 0.61875, ((3, 0), 'exit'): -5.0, ((1, 4), 'east'): 0.1390510546875, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 8.672607421875, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.04613203125000001, ((1, 4), 'west'): 0.031139121093750007, ((1, 1), 'east'): 1.21488134765625, ((0, 4), 'north'): 0.03892390136718751, ((2, 1), 'west'): 0.4498940917968751, ((0, 4), 'south'): 0.018683472656250005, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 0.9852890625, ((1, 4), 'south'): 0.060548291015625005, ((4, 3), 'east'): 0.0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 6.428485107421876, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.07688671875000001, ((0, 4), 'east'): 0.05894648437500001, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.421875, ((4, 3), 'south'): 8.896728515625}

##################################

AVERAGE RETURNS FROM START STATE: 0.00901646036792


Traceback (most recent call last):
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/Users/lguan/Documents/Study/Research/Summer 2018/Week5/BerkeleyGridWorld/experiment/expr_launcher_terminal.py", line 80, in <module>
    run_expr()
  File "/Users/lguan/Documents/Study/Research/Summer 2018/Week5/BerkeleyGridWorld/experiment/expr_launcher_terminal.py", line 76, in run_expr
    tamerGridWorld.run_episodes()
  File "BerkeleyGridWorld/gridworld.py", line 732, in run_episodes
    plotRatios(policy_converge_ratios)
  File "BerkeleyGridWorld/gridworld.py", line 758, in plotRatios
    plt.show()
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/site-packages/matplotlib/pyplot.py", line 253, in show
    return _show(*args, **kw)
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/site-packages/matplotlib/backend_bases.py", line 208, in show
    cls.mainloop()
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/site-packages/matplotlib/backends/_backend_tk.py", line 1073, in mainloop
    Tk.mainloop()
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/lib-tk/Tkinter.py", line 419, in mainloop
    _default_root.tk.mainloop(n)
KeyboardInterrupt
