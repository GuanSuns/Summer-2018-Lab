*************************************
*************************************
*************************************
*** Start Sub-Experiment 0 **********
*************************************
*************************************
*************************************

RUNNING 800 EPISODES

Traceback (most recent call last):
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/Users/lguan/Documents/Study/Research/Summer 2018/Week8/BerkeleyGridWorld/experiment/expr_launcher_terminal.py", line 167, in <module>
    run_experiments()
  File "/Users/lguan/Documents/Study/Research/Summer 2018/Week8/BerkeleyGridWorld/experiment/expr_launcher_terminal.py", line 161, in run_experiments
    , is_use_q_learning_agent=is_use_q_learning_agent)
  File "/Users/lguan/Documents/Study/Research/Summer 2018/Week8/BerkeleyGridWorld/experiment/expr_launcher_terminal.py", line 119, in run_expr
    experiment_stat = tamerGridWorld.run_episodes()
  File "BerkeleyGridWorld/gridworld.py", line 789, in run_episodes
    , optimal_policy=self.optimal_policy)
  File "BerkeleyGridWorld/gridworld.py", line 585, in runEpisode
    , is_print_info=False)
  File "BerkeleyGridWorld/gridworld.py", line 498, in getPolicyAgreementRatio
    optimal_actions = getSelectedActions(m_environment, state, optimal_qValues)
  File "BerkeleyGridWorld/gridworld.py", line 485, in getSelectedActions
    action_qValues = [round(qValues[(state, possible_actions[j])], 4) for j in range(0, n_actions)]
KeyboardInterrupt
