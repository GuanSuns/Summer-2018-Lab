*************************************
*************************************
*************************************
*** Start Sub-Experiment 0 **********
*************************************
*************************************
*************************************

RUNNING 800 EPISODES

BEGINNING EPISODE: 1

Current Policy Agreement Ratio: 0.000000
Step: 0, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 1, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 2, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 3, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 4, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 5, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 6, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 7, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 8, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 9, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 10, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 11, S: (0, 3), A: south, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 12, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 13, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 14, S: (0, 3), A: south, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 15, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 16, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 17, S: (1, 1), A: south, S': (1, 0), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 18, S: (1, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.000000
--------------------------------
EPISODE 1 COMPLETE: RETURN WAS -1.50094635297

TOTAL STEPS: 19, EPISODE STEPS: 19
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 0, ((2, 4), 'east'): 0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0, ((3, 3), 'north'): 0, ((3, 4), 'north'): 0, ((4, 4), 'north'): 0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0, ((4, 4), 'west'): 0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -3.0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0.0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0, ((4, 1), 'north'): 0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0, ((1, 4), 'south'): 0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0, ((4, 1), 'east'): 0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Action 'north' at state (3, 3) is not optimal
Action 'north' at state (3, 4) is not optimal
Action 'west' at state (4, 1) is not optimal
Action 'north' at state (4, 3) is not optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.000000
################################

BEGINNING EPISODE: 2

Current Policy Agreement Ratio: 0.000000
Step: 0, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 1, S: (4, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 2, S: (4, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 3, S: (4, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 4, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 5, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.000000
--------------------------------
EPISODE 2 COMPLETE: RETURN WAS 5.9049

TOTAL STEPS: 25, EPISODE STEPS: 6
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 3.0, ((2, 4), 'east'): 0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0, ((3, 3), 'north'): 0, ((3, 4), 'north'): 0, ((4, 4), 'north'): 0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0, ((3, 3), 'west'): 0, ((4, 4), 'west'): 0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -3.0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0, ((1, 1), 'south'): 0.0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0, ((1, 4), 'south'): 0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Action 'north' at state (3, 3) is not optimal
Action 'north' at state (3, 4) is not optimal
Action 'west' at state (4, 1) is not optimal
Action 'north' at state (4, 3) is not optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.000000
################################

BEGINNING EPISODE: 3

Current Policy Agreement Ratio: 0.000000
Step: 0, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 1, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 2, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 3, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 4, S: (2, 3), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 5, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 6, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 7, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 8, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 9, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 10, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 11, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 12, S: (4, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 13, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 14, S: (3, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 15, S: (3, 3), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 16, S: (3, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 17, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 18, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 19, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 20, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 21, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 22, S: (1, 4), A: south, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 23, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 24, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 25, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 26, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 27, S: (0, 3), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 28, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 29, S: (0, 4), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 30, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 31, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 32, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 33, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 34, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 35, S: (0, 3), A: south, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 36, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 37, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 38, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 39, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 40, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 41, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 42, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 43, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 44, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 45, S: (0, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 46, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 47, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 48, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 49, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 50, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 51, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 52, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 53, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 54, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.000000
--------------------------------
EPISODE 3 COMPLETE: RETURN WAS 0.00338139191352

TOTAL STEPS: 80, EPISODE STEPS: 55
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 3.0, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.3, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -3.0, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): 0.0, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Action 'north' at state (3, 3) is not optimal
Action 'north' at state (3, 4) is not optimal
Action 'west' at state (4, 1) is not optimal
Action 'north' at state (4, 3) is not optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.000000
################################

BEGINNING EPISODE: 4

Current Policy Agreement Ratio: 0.000000
Step: 0, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 1, S: (0, 2), A: west, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 2, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 3, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 4, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 5, S: (1, 1), A: south, S': (1, 0), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 6, S: (1, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.000000
--------------------------------
EPISODE 4 COMPLETE: RETURN WAS -5.31441

TOTAL STEPS: 87, EPISODE STEPS: 7
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 3.0, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.3, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Action 'north' at state (3, 3) is not optimal
Action 'north' at state (3, 4) is not optimal
Action 'west' at state (4, 1) is not optimal
Action 'north' at state (4, 3) is not optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.000000
################################

BEGINNING EPISODE: 5

Current Policy Agreement Ratio: 0.000000
Step: 0, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 1, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 2, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 3, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 4, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 5, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 6, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 7, S: (0, 4), A: south, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 8, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 9, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 10, S: (0, 4), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 11, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 12, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 13, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 14, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 15, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 16, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 17, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 18, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 19, S: (0, 3), A: west, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 20, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 21, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 22, S: (0, 3), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 23, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 24, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 25, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 26, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 27, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 28, S: (1, 4), A: south, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 29, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 30, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 31, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 32, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 33, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 34, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 35, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 36, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.000000
Step: 37, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 38, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.066667
--------------------------------
EPISODE 5 COMPLETE: RETURN WAS 0.182480036314

TOTAL STEPS: 126, EPISODE STEPS: 39
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): 0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 5.1, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0, ((4, 1), 'south'): 0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.3, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0.81}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Action 'north' at state (3, 3) is not optimal
Action 'north' at state (3, 4) is not optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.066667
################################

BEGINNING EPISODE: 6

Current Policy Agreement Ratio: 0.066667
Step: 0, S: (4, 1), A: south, S': (4, 0), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 1, S: (4, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.066667
--------------------------------
EPISODE 6 COMPLETE: RETURN WAS -9.0

TOTAL STEPS: 128, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 5.1, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.3, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): 0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0.81}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Action 'north' at state (3, 3) is not optimal
Action 'north' at state (3, 4) is not optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.066667
################################

BEGINNING EPISODE: 7

Current Policy Agreement Ratio: 0.066667
Step: 0, S: (3, 1), A: south, S': (3, 0), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 1, S: (3, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.066667
--------------------------------
EPISODE 7 COMPLETE: RETURN WAS -9.0

TOTAL STEPS: 130, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 5.1, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0, ((0, 2), 'east'): 0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.3, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0, ((3, 3), 'east'): 0.0, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 0.81}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Action 'north' at state (3, 3) is not optimal
Action 'north' at state (3, 4) is not optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.066667
################################

BEGINNING EPISODE: 8

Current Policy Agreement Ratio: 0.066667
Step: 0, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 1, S: (1, 1), A: west, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 2, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 3, S: (0, 2), A: east, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 4, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 5, S: (0, 2), A: east, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 6, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 7, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 8, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 9, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 10, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 11, S: (0, 3), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 12, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 13, S: (0, 3), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 14, S: (0, 3), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 15, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 16, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 17, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 18, S: (0, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 19, S: (0, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 20, S: (1, 4), A: south, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 21, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 22, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 23, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 24, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 25, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 26, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 27, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 28, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 29, S: (1, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 30, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 31, S: (0, 4), A: south, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 32, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 33, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 34, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 35, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 36, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 37, S: (2, 3), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 38, S: (2, 4), A: east, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 39, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.066667
Step: 40, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 41, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 42, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.133333
--------------------------------
EPISODE 8 COMPLETE: RETURN WAS 0.119725151826

TOTAL STEPS: 173, EPISODE STEPS: 43
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 6.569999999999999, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.0, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.3, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 0.21870000000000003, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.0, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 1.944}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Action 'north' at state (3, 4) is not optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.133333
################################

BEGINNING EPISODE: 9

Current Policy Agreement Ratio: 0.133333
Step: 0, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 1, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 2, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 3, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 4, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 5, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 6, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 7, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 8, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 9, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 10, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 11, S: (1, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 12, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 13, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 14, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 15, S: (2, 3), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 16, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 17, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 18, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 19, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 20, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 21, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 22, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 23, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 24, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 25, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 26, S: (2, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 27, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 28, S: (1, 4), A: south, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 29, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 30, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 31, S: (4, 4), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 32, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 33, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 34, S: (2, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.133333
Step: 35, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.200000
Step: 36, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.200000
Step: 37, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.200000
Step: 38, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.200000
Step: 39, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.200000
--------------------------------
EPISODE 9 COMPLETE: RETURN WAS 0.164232032683

TOTAL STEPS: 213, EPISODE STEPS: 40
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 7.598999999999999, ((2, 4), 'east'): 0.0, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.3, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.0, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 0.67797, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.0, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.059049000000000004, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 3.1346999999999996}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'north' at state (2, 3) is not optimal
Action 'north' at state (2, 4) is not optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'north' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.200000
################################

BEGINNING EPISODE: 10

Current Policy Agreement Ratio: 0.200000
Step: 0, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 1, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 2, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 3, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 4, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 5, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 6, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.266667
--------------------------------
EPISODE 10 COMPLETE: RETURN WAS 0.531441

TOTAL STEPS: 220, EPISODE STEPS: 7
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 7.598999999999999, ((2, 4), 'east'): 0.015943230000000003, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.51, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 0.67797, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.081, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.059049000000000004, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0, ((4, 3), 'south'): 3.1346999999999996}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.266667
################################

BEGINNING EPISODE: 11

Current Policy Agreement Ratio: 0.266667
Step: 0, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 1, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.266667
--------------------------------
EPISODE 11 COMPLETE: RETURN WAS 0.9

TOTAL STEPS: 222, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 7.598999999999999, ((2, 4), 'east'): 0.015943230000000003, ((0, 1), 'south'): 0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.657, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 0.67797, ((0, 0), 'exit'): 0, ((2, 3), 'south'): 0.081, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.059049000000000004, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 3.1346999999999996}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.266667
################################

BEGINNING EPISODE: 12

Current Policy Agreement Ratio: 0.266667
Step: 0, S: (0, 3), A: east, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 1, S: (0, 2), A: east, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 2, S: (0, 1), A: south, S': (0, 0), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 3, S: (0, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.266667
--------------------------------
EPISODE 12 COMPLETE: RETURN WAS -7.29

TOTAL STEPS: 226, EPISODE STEPS: 4
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 7.598999999999999, ((2, 4), 'east'): 0.015943230000000003, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.657, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 0.67797, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.081, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.0, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.059049000000000004, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 3.1346999999999996}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Action 'north' at state (1, 4) is not optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.266667
################################

BEGINNING EPISODE: 13

Current Policy Agreement Ratio: 0.266667
Step: 0, S: (0, 4), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 1, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 2, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 3, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 4, S: (1, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.266667
Step: 5, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 6, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 7, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 8, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 9, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 10, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.333333
--------------------------------
EPISODE 13 COMPLETE: RETURN WAS 3.486784401

TOTAL STEPS: 237, EPISODE STEPS: 11
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 8.319299999999998, ((2, 4), 'east'): 0.027103491000000004, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.657, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 1.3209479999999998, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.081, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.0043046721, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.22438619999999998, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 4.24602}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.333333
################################

BEGINNING EPISODE: 14

Current Policy Agreement Ratio: 0.333333
Step: 0, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 1, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.333333
--------------------------------
EPISODE 14 COMPLETE: RETURN WAS 0.9

TOTAL STEPS: 239, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 8.319299999999998, ((2, 4), 'east'): 0.027103491000000004, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.7599, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 1.3209479999999998, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.23409000000000002, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.0043046721, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.0, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.22438619999999998, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 4.24602}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.333333
################################

BEGINNING EPISODE: 15

Current Policy Agreement Ratio: 0.333333
Step: 0, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 1, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 2, S: (2, 4), A: east, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 3, S: (2, 3), A: west, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 4, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 5, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.333333
--------------------------------
EPISODE 15 COMPLETE: RETURN WAS 0.59049

TOTAL STEPS: 245, EPISODE STEPS: 6
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 8.319299999999998, ((2, 4), 'east'): 0.0821767437, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.8319300000000001, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -5.1, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -0.81, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 1.3209479999999998, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.36903600000000003, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.010331213040000002, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.22438619999999998, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 4.24602}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.333333
################################

BEGINNING EPISODE: 16

Current Policy Agreement Ratio: 0.333333
Step: 0, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 1, S: (1, 1), A: south, S': (1, 0), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 2, S: (1, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.333333
--------------------------------
EPISODE 16 COMPLETE: RETURN WAS -8.1

TOTAL STEPS: 248, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 8.319299999999998, ((2, 4), 'east'): 0.0821767437, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.8319300000000001, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 1.3209479999999998, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.36903600000000003, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.010331213040000002, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.22438619999999998, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 4.24602}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.333333
################################

BEGINNING EPISODE: 17

Current Policy Agreement Ratio: 0.333333
Step: 0, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 1, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.333333
--------------------------------
EPISODE 17 COMPLETE: RETURN WAS 9.0

TOTAL STEPS: 250, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): 0, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 8.823509999999999, ((2, 4), 'east'): 0.0821767437, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.8319300000000001, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 1.3209479999999998, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.36903600000000003, ((3, 0), 'exit'): -3.0, ((1, 4), 'east'): 0.010331213040000002, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.22438619999999998, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 5.218424999999999}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.333333
################################

BEGINNING EPISODE: 18

Current Policy Agreement Ratio: 0.333333
Step: 0, S: (4, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 1, S: (4, 1), A: west, S': (3, 1), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 2, S: (3, 1), A: west, S': (3, 0), R: 0.0

Current Policy Agreement Ratio: 0.333333
Step: 3, S: (3, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.333333
--------------------------------
EPISODE 18 COMPLETE: RETURN WAS -7.29

TOTAL STEPS: 254, EPISODE STEPS: 4
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 8.823509999999999, ((2, 4), 'east'): 0.0821767437, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.8319300000000001, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 1.3209479999999998, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.36903600000000003, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.010331213040000002, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.22438619999999998, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 5.218424999999999}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Action 'north' at state (0, 4) is not optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.333333
################################

BEGINNING EPISODE: 19

Current Policy Agreement Ratio: 0.333333
Step: 0, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 1, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 2, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 3, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 4, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 5, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 6, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 7, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.400000
--------------------------------
EPISODE 19 COMPLETE: RETURN WAS 4.782969

TOTAL STEPS: 262, EPISODE STEPS: 8
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.176457, ((2, 4), 'east'): 0.11810799458999999, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.8319300000000001, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.015943230000000003, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 2.3336383499999993, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.36903600000000003, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.029202614453159997, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.5137262999999999, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0027894275208000005, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 6.0352451999999985}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.400000
################################

BEGINNING EPISODE: 20

Current Policy Agreement Ratio: 0.400000
Step: 0, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 1, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 2, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 3, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 4, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 5, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 6, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.400000
--------------------------------
EPISODE 20 COMPLETE: RETURN WAS 5.31441

TOTAL STEPS: 269, EPISODE STEPS: 7
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.423519899999999, ((2, 4), 'east'): 0.22138169721299994, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.8319300000000001, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0043046721, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.14986636199999998, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 3.263063048999999, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.36903600000000003, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.029202614453159997, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.9896907644999996, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0027894275208000005, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.1377, ((4, 3), 'south'): 6.7023150299999985}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.400000
################################

BEGINNING EPISODE: 21

Current Policy Agreement Ratio: 0.400000
Step: 0, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 1, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.400000
--------------------------------
EPISODE 21 COMPLETE: RETURN WAS 0.9

TOTAL STEPS: 271, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0, ((4, 2), 'exit'): 9.423519899999999, ((2, 4), 'east'): 0.22138169721299994, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.8823509999999999, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0043046721, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.0, ((4, 4), 'west'): 0.14986636199999998, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.0, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 3.263063048999999, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.36903600000000003, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.029202614453159997, ((4, 3), 'west'): 0.0, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 0.9896907644999996, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0027894275208000005, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.3210111, ((4, 3), 'south'): 6.7023150299999985}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Action 'west' at state (0, 3) is not optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.400000
################################

BEGINNING EPISODE: 22

Current Policy Agreement Ratio: 0.400000
Step: 0, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 1, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 2, S: (1, 1), A: west, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 3, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 4, S: (0, 2), A: east, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 5, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.400000
Step: 6, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 7, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 8, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 9, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 10, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 11, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 12, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 13, S: (4, 3), A: west, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 14, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 15, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 16, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 17, S: (4, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 18, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 19, S: (2, 3), A: south, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 20, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.466667
--------------------------------
EPISODE 22 COMPLETE: RETURN WAS 0.121576654591

TOTAL STEPS: 292, EPISODE STEPS: 21
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.423519899999999, ((2, 4), 'east'): 0.42218369446409987, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9176456999999998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0043046721, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 0.5298353041625998, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 4.675263492779997, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.08021488836472199, ((4, 3), 'west'): 1.2906458854685992, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 2.206985072813999, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 0, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0098373051669132, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.3210111, ((4, 3), 'south'): 6.7023150299999985}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.466667
################################

BEGINNING EPISODE: 23

Current Policy Agreement Ratio: 0.466667
Step: 0, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 1, S: (4, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 2, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 3, S: (4, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 4, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 5, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.466667
--------------------------------
EPISODE 23 COMPLETE: RETURN WAS 5.9049

TOTAL STEPS: 298, EPISODE STEPS: 6
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.596463929999999, ((2, 4), 'east'): 0.42218369446409987, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9176456999999998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0043046721, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 0.5298353041625998, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 5.367241710232198, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.08021488836472199, ((4, 3), 'west'): 2.2756756856504388, ((4, 1), 'north'): 0.0, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0, ((3, 4), 'south'): 2.206985072813999, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 1.8096250580999995, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0098373051669132, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.3210111, ((4, 3), 'south'): 7.235970893999999}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Action 'west' at state (4, 1) is not optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.466667
################################

BEGINNING EPISODE: 24

Current Policy Agreement Ratio: 0.466667
Step: 0, S: (3, 1), A: north, S': (3, 1), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 1, S: (3, 1), A: north, S': (3, 1), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 2, S: (3, 1), A: north, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.466667
Step: 3, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 4, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.533333
--------------------------------
EPISODE 24 COMPLETE: RETURN WAS 6.561

TOTAL STEPS: 303, EPISODE STEPS: 5
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.717524751, ((2, 4), 'east'): 0.42218369446409987, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.0, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9176456999999998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0043046721, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 0.5298353041625998, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 5.367241710232198, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.08021488836472199, ((4, 3), 'west'): 2.2756756856504388, ((4, 1), 'north'): 2.5910452610999997, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 2.206985072813999, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 1.8096250580999995, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0098373051669132, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.3210111, ((4, 3), 'south'): 7.235970893999999}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.533333
################################

BEGINNING EPISODE: 25

Current Policy Agreement Ratio: 0.533333
Step: 0, S: (4, 4), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 1, S: (4, 4), A: west, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 2, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 3, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 4, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 5, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 6, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.533333
--------------------------------
EPISODE 25 COMPLETE: RETURN WAS 5.31441

TOTAL STEPS: 310, EPISODE STEPS: 7
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.802267325699999, ((2, 4), 'east'): 0.42218369446409987, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9176456999999998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0043046721, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 0.9556441411861849, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 5.710781338542539, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.08021488836472199, ((4, 3), 'west'): 2.2756756856504388, ((4, 1), 'north'): 2.5910452610999997, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 2.9940448127324926, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 1.8096250580999995, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0098373051669132, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.3210111, ((4, 3), 'south'): 7.688911308569999}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.533333
################################

BEGINNING EPISODE: 26

Current Policy Agreement Ratio: 0.533333
Step: 0, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 1, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 2, S: (3, 3), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 3, S: (3, 4), A: south, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 4, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 5, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 6, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 7, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 8, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.533333
--------------------------------
EPISODE 26 COMPLETE: RETURN WAS 4.3046721

TOTAL STEPS: 319, EPISODE STEPS: 9
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.86158712799, ((2, 4), 'east'): 0.42218369446409987, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.0, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9176456999999998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 0.0043046721, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 1.8293717037917507, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 5.561822209630078, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.08021488836472199, ((4, 3), 'west'): 2.2756756856504388, ((4, 1), 'north'): 2.5910452610999997, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.0043046721, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 3.406240657393905, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 1.8096250580999995, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0098373051669132, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.3210111, ((4, 3), 'south'): 8.028850093937999}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.533333
################################

BEGINNING EPISODE: 27

Current Policy Agreement Ratio: 0.533333
Step: 0, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 1, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 3, S: (3, 3), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 4, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 5, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 6, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 7, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 8, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 9, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 10, S: (3, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 11, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 12, S: (3, 4), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 13, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 14, S: (4, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 15, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 16, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 17, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.533333
--------------------------------
EPISODE 27 COMPLETE: RETURN WAS 1.66771816997

TOTAL STEPS: 337, EPISODE STEPS: 18
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.903110989593, ((2, 4), 'east'): 2.0679867311073314, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.37538184450158496, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9176456999999998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 2.6349461607641835, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 6.442740631979731, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.08021488836472199, ((4, 3), 'west'): 3.241882692507375, ((4, 1), 'north'): 2.5910452610999997, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 4.054720524662142, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 1.8096250580999995, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.9398174479572974, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0098373051669132, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.3210111, ((4, 3), 'south'): 8.2828235903139}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.533333
################################

BEGINNING EPISODE: 28

Current Policy Agreement Ratio: 0.533333
Step: 0, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 1, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.533333
--------------------------------
EPISODE 28 COMPLETE: RETURN WAS 0.9

TOTAL STEPS: 339, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.903110989593, ((2, 4), 'east'): 2.0679867311073314, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.37538184450158496, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 2.6349461607641835, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 6.442740631979731, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.08021488836472199, ((4, 3), 'west'): 3.241882692507375, ((4, 1), 'north'): 2.5910452610999997, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 4.054720524662142, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 1.8096250580999995, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.9398174479572974, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.0, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0098373051669132, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.2828235903139}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.533333
################################

BEGINNING EPISODE: 29

Current Policy Agreement Ratio: 0.533333
Step: 0, S: (3, 1), A: north, S': (3, 1), R: 0.0

Current Policy Agreement Ratio: 0.533333
Step: 1, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 2, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 3, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.600000
--------------------------------
EPISODE 29 COMPLETE: RETURN WAS 7.29

TOTAL STEPS: 343, EPISODE STEPS: 4
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.932177692715099, ((2, 4), 'east'): 2.0679867311073314, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.37538184450158496, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 2.6349461607641835, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 6.442740631979731, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.08021488836472199, ((4, 3), 'west'): 3.241882692507375, ((4, 1), 'north'): 4.48757164996011, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.001162261467, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 4.054720524662142, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 1.8096250580999995, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.9398174479572974, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.6995822204969999, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.0098373051669132, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.2828235903139}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.600000
################################

BEGINNING EPISODE: 30

Current Policy Agreement Ratio: 0.600000
Step: 0, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 1, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 2, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 3, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 4, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 5, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 6, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 7, S: (4, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 8, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 9, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.600000
--------------------------------
EPISODE 30 COMPLETE: RETURN WAS 3.87420489

TOTAL STEPS: 353, EPISODE STEPS: 10
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.952524384900569, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 0.0, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 0.059049000000000004, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 0.37538184450158496, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.09963972000000001, ((4, 4), 'west'): 2.6349461607641835, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 6.746280811770564, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 3.241882692507375, ((4, 1), 'north'): 4.48757164996011, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 4.577844337898027, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 3.503099910054752, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 0.9398174479572974, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.6995822204969999, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.479664490252805}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Action 'south' at state (2, 3) is not optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.600000
################################

BEGINNING EPISODE: 31

Current Policy Agreement Ratio: 0.600000
Step: 0, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (4, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 13, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 14, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 15, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 16, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 17, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 18, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 19, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 31 COMPLETE: RETURN WAS 1.35085171767

TOTAL STEPS: 373, EPISODE STEPS: 20
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.966767069430396, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 3.1729676960606605, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 1.9345489147640662, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 3.533464149265866, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.034359482218955, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 3.241882692507375, ((4, 1), 'north'): 4.48757164996011, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 5.46825234648818, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 1.7902450505007033, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.6995822204969999, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.167467414481873}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 32

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 32 COMPLETE: RETURN WAS 5.9049

TOTAL STEPS: 379, EPISODE STEPS: 6
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.976736948601278, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 3.1729676960606605, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 3.533464149265866, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.195703689534467, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 4.194220201410273, ((4, 1), 'north'): 4.48757164996011, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 5.46825234648818, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 1.7902450505007033, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 0.6995822204969999, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.408254298883516}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 33

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 1), A: north, S': (3, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 33 COMPLETE: RETURN WAS 6.561

TOTAL STEPS: 384, EPISODE STEPS: 5
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.983715864020894, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 3.1729676960606605, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 3.533464149265866, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.195703689534467, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 4.194220201410273, ((4, 1), 'north'): 5.214184593672016, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 5.46825234648818, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 1.7902450505007033, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.408254298883516}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 34

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 34 COMPLETE: RETURN WAS 7.29

TOTAL STEPS: 388, EPISODE STEPS: 4
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.988601104814625, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 3.533464149265866, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.307221243372676, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 4.194220201410273, ((4, 1), 'north'): 5.214184593672016, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 0.0, ((3, 4), 'south'): 5.46825234648818, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 1.7902450505007033, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.581381292504103}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 35

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 1), A: north, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 35 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 391, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.992020773370237, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 0.14305553212390196, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 3.533464149265866, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.307221243372676, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 4.194220201410273, ((4, 1), 'north'): 6.34685151387036, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 5.46825234648818, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 1.7902450505007033, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.581381292504103}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 36

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 4), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 36 COMPLETE: RETURN WAS 4.782969

TOTAL STEPS: 399, EPISODE STEPS: 8
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.994414541359166, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9423519899999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 3.9498530380379147, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.519392422511993, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.34685151387036, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 5.800726378252348, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 1.7902450505007033, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.4724721089999999, ((4, 3), 'south'): 8.704812513562835}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 37

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 37 COMPLETE: RETURN WAS 0.9

TOTAL STEPS: 401, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.994414541359166, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9596463929999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 3.9498530380379147, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.519392422511993, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.34685151387036, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 5.800726378252348, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 1.7902450505007033, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.5851655135999998, ((4, 3), 'south'): 8.704812513562835}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 38

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 38 COMPLETE: RETURN WAS 0.9

TOTAL STEPS: 403, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.994414541359166, ((2, 4), 'east'): 2.54236525343391, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9717524750999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 3.9498530380379147, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.519392422511993, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 0.9885112048769789, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.34685151387036, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 5.800726378252348, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 1.7902450505007033, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.6687203856299997, ((4, 3), 'south'): 8.704812513562835}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 39

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 39 COMPLETE: RETURN WAS 3.486784401

TOTAL STEPS: 414, EPISODE STEPS: 11
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.996090178951416, ((2, 4), 'east'): 3.3458517995318706, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9717524750999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.409398119717359, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.569476162145291, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 1.378396461841041, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.34685151387036, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.2766321382562715, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.6687203856299997, ((4, 3), 'south'): 8.791860685660959}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 40

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 40 COMPLETE: RETURN WAS 6.561

TOTAL STEPS: 419, EPISODE STEPS: 5
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.997263125265992, ((2, 4), 'east'): 3.3458517995318706, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9717524750999997, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.781269361131344, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.672435698630162, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 1.378396461841041, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.34685151387036, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.437401060558619, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.6687203856299997, ((4, 3), 'south'): 8.853246828279554}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 41

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 41 COMPLETE: RETURN WAS 0.9

TOTAL STEPS: 421, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.997263125265992, ((2, 4), 'east'): 3.3458517995318706, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.781269361131344, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.672435698630162, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 1.378396461841041, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.34685151387036, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.437401060558619, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.163125925226578, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.853246828279554}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 42

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 1), A: north, S': (3, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 42 COMPLETE: RETURN WAS 7.29

TOTAL STEPS: 425, EPISODE STEPS: 4
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.998084187686194, ((2, 4), 'east'): 3.3458517995318706, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.781269361131344, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.672435698630162, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 1.378396461841041, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.218049085486117, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.437401060558619, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.853246828279554}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 43

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 43 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 428, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.0007531454306160001, ((4, 2), 'exit'): 9.998658931380335, ((2, 4), 'east'): 3.3458517995318706, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.0, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.781269361131344, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.761081632676593, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 1.378396461841041, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.218049085486117, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.0, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 0.11700286797530696, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.437401060558619, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.028544133475314176, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.89675551047096}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 44

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 4), A: east, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (3, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 13, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 14, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 15, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 44 COMPLETE: RETURN WAS 2.05891132095

TOTAL STEPS: 444, EPISODE STEPS: 16
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 0, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999061251966236, ((2, 4), 'east'): 4.594234468567022, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.3610020333561686, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.781269361131344, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.834881130700774, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 1.8393111834636717, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.218049085486117, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.10587994329504626, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.601672783213713, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.5644618788670699, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.927366768802363}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 45

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 4), A: south, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 45 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 447, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999342876376364, ((2, 4), 'east'): 4.594234468567022, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 3.279086556989957, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 0.0, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.3610020333561686, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 0.0, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.781269361131344, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.834881130700774, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 1.8393111834636717, ((4, 3), 'west'): 4.942601652208175, ((4, 1), 'north'): 6.218049085486117, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.10587994329504626, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.601672783213713, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.5644618788670699, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.948903276192537}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 46

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (2, 3), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 46 COMPLETE: RETURN WAS 3.486784401

TOTAL STEPS: 458, EPISODE STEPS: 11
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999540013463454, ((2, 4), 'east'): 4.998415779464618, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 4.4107784951821785, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.3610020333561686, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.781269361131344, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.946638357815754, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 2.527961134937666, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 6.218049085486117, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.10587994329504626, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.736588853538808, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.5644618788670699, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.964054869956394}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 47

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 47 COMPLETE: RETURN WAS 9.0

TOTAL STEPS: 460, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999678009424418, ((2, 4), 'east'): 4.998415779464618, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 4.4107784951821785, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.3610020333561686, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 4.781269361131344, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.946638357815754, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 2.527961134937666, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.10587994329504626, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.736588853538808, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 4.741679349406583, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.5644618788670699, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.964054869956394}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 48

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (4, 3), A: east, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 48 COMPLETE: RETURN WAS 6.561

TOTAL STEPS: 465, EPISODE STEPS: 5
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999774606597093, ((2, 4), 'east'): 4.998415779464618, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 4.4107784951821785, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.3610020333561686, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 7.982941665359254, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 2.527961134937666, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.10587994329504626, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.8612045540874185, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 6.019088607129201, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.5644618788670699, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.964054869956394}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 49

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 3), A: east, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 49 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 468, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999842224617964, ((2, 4), 'east'): 4.998415779464618, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 4.4107784951821785, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 0.3610020333561686, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 8.008353980639704, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 2.527961134937666, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.10587994329504626, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.8612045540874185, ((1, 4), 'south'): 0.0, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 0.5644618788670699, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.964054869956394}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 50

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (1, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 13, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 50 COMPLETE: RETURN WAS 2.54186582833

TOTAL STEPS: 482, EPISODE STEPS: 14
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999889557232574, ((2, 4), 'east'): 5.351416275228836, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 4.4107784951821785, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 1.337225157280911, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -6.569999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): 0.0, ((3, 3), 'east'): 8.02614260133602, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 3.0145633027594414, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.8007752979234182, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.965098762633913, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 1.0571963364471233, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.974795809616325}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 51

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 1), A: west, S': (1, 0), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (1, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 51 COMPLETE: RETURN WAS -9.0

TOTAL STEPS: 484, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999889557232574, ((2, 4), 'east'): 5.351416275228836, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 4.4107784951821785, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 1.337225157280911, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.02614260133602, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 3.0145633027594414, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.8007752979234182, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.965098762633913, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 1.0571963364471233, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.974795809616325}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 52

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 52 COMPLETE: RETURN WAS 4.782969

TOTAL STEPS: 492, EPISODE STEPS: 8
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999922690062801, ((2, 4), 'east'): 5.626568058571341, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.25460344898825, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 1.337225157280911, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.041494689531621, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 3.555076706243394, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.8007752979234182, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.042627636204463, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 1.5539695272580354, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.982327247184221}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 53

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 53 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 495, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.99994588304396, ((2, 4), 'east'): 5.626568058571341, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 4.163917383416768, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.25460344898825, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 1.337225157280911, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 0.561551675178074, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.054274639411874, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 3.555076706243394, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.8007752979234182, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.042627636204463, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 1.5539695272580354, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.98760819934591}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 54

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 54 COMPLETE: RETURN WAS 4.3046721

TOTAL STEPS: 504, EPISODE STEPS: 9
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.07469806640985549, ((4, 2), 'exit'): 9.999962118130771, ((2, 4), 'east'): 5.840107102775144, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 5.089396321032943, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 1.337225157280911, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 1.5173438661471792, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.064646461411707, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 4.007727070184638, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.8007752979234182, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.104493497984329, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 1.5539695272580354, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.991311127964005}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 55

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 55 COMPLETE: RETURN WAS 4.3046721

TOTAL STEPS: 513, EPISODE STEPS: 9
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.47186041884656843, ((4, 2), 'exit'): 9.999973482691539, ((2, 4), 'east'): 6.006288216398369, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 5.089396321032943, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 1.337225157280911, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 1.5173438661471792, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 0.05977305824750999, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.072906527538475, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 4.298075598404657, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 0.8007752979234182, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.15059999317019, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 2.1698649780304766, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.993907561470111}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 56

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (2, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (2, 4), A: east, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 56 COMPLETE: RETURN WAS 3.486784401

TOTAL STEPS: 524, EPISODE STEPS: 11
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.47186041884656843, ((4, 2), 'exit'): 9.999981437884077, ((2, 4), 'east'): 5.578538758157753, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 5.742262187158448, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 1.5173438661471792, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.079389610873863, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 4.8629433345451325, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.15059999317019, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 2.679385896190591, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.995728133355794}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 57

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 4), A: south, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 57 COMPLETE: RETURN WAS 5.9049

TOTAL STEPS: 530, EPISODE STEPS: 6
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.47186041884656843, ((4, 2), 'exit'): 9.999987006518854, ((2, 4), 'east'): 5.663116004889293, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 5.742262187158448, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 1.5173438661471792, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.084419323617768, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 4.8629433345451325, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.739573016881151, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 2.679385896190591, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.997004681577756}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 58

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 58 COMPLETE: RETURN WAS 9.0

TOTAL STEPS: 532, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.47186041884656843, ((4, 2), 'exit'): 9.999990904563198, ((2, 4), 'east'): 5.663116004889293, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 5.742262187158448, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 1.5173438661471792, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.084419323617768, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 4.8629433345451325, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.739573016881151, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 2.679385896190591, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.997899768864519}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 59

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 59 COMPLETE: RETURN WAS 5.9049

TOTAL STEPS: 538, EPISODE STEPS: 6
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.47186041884656843, ((4, 2), 'exit'): 9.999993633194238, ((2, 4), 'east'): 5.783865917980416, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 5.742262187158448, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 1.5173438661471792, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.088526464125858, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 4.9331016555017015, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.900494329193602, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 2.679385896190591, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.998527382437228}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 60

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 60 COMPLETE: RETURN WAS 5.31441

TOTAL STEPS: 545, EPISODE STEPS: 7
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 0.47186041884656843, ((4, 2), 'exit'): 9.999995543235967, ((2, 4), 'east'): 5.911839611468563, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 5.742262187158448, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.0, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 1.5173438661471792, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.091570918146152, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 5.014814956705903, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.014248175749502, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 6.913301168771656, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 3.207507574318873, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.998967448668504}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 61

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (4, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 13, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 61 COMPLETE: RETURN WAS 2.54186582833

TOTAL STEPS: 559, EPISODE STEPS: 14
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 1.1963293382586937, ((4, 2), 'exit'): 9.999996880265176, ((2, 4), 'east'): 6.03213473548036, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 6.204307678910374, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.12740231308857347, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.165767543247419, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.093820853842802, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 5.00125605069982, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.094697870924112, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 2.319631855620729, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 3.599255340333805, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.999276010741664}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 62

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 62 COMPLETE: RETURN WAS 3.1381059609

TOTAL STEPS: 571, EPISODE STEPS: 12
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 1.809229478671213, ((4, 2), 'exit'): 9.999997816185623, ((2, 4), 'east'): 6.138062739985761, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 6.204307678910374, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.12740231308857347, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.54697471812299, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.096639907313396, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 5.129555614069571, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.191913460688459, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.0184995356113133, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 3.8698178719226144, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.999492365190761}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 63

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 63 COMPLETE: RETURN WAS 9.0

TOTAL STEPS: 573, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 1.809229478671213, ((4, 2), 'exit'): 9.999998471329935, ((2, 4), 'east'): 6.138062739985761, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 6.204307678910374, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.12740231308857347, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.54697471812299, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): 0.0, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.096639907313396, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -5.1, ((1, 4), 'east'): 5.129555614069571, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.191913460688459, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.0184995356113133, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 3.8698178719226144, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.99964406600365}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 64

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 1), A: south, S': (3, 0), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 64 COMPLETE: RETURN WAS -9.0

TOTAL STEPS: 575, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 1.809229478671213, ((4, 2), 'exit'): 9.999998471329935, ((2, 4), 'east'): 6.138062739985761, ((0, 1), 'south'): 0.0, ((2, 3), 'east'): 6.204307678910374, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.12740231308857347, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.54697471812299, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.096639907313396, ((0, 0), 'exit'): -3.0, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.129555614069571, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.191913460688459, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.0184995356113133, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 3.8698178719226144, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.99964406600365}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 65

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 1), A: south, S': (0, 0), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 65 COMPLETE: RETURN WAS -9.0

TOTAL STEPS: 577, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 1.809229478671213, ((4, 2), 'exit'): 9.999998471329935, ((2, 4), 'east'): 6.138062739985761, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.204307678910374, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.12740231308857347, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.54697471812299, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.096639907313396, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.129555614069571, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.0525101634754135, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.191913460688459, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.0184995356113133, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 3.8698178719226144, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.99964406600365}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 66

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 66 COMPLETE: RETURN WAS 9.0

TOTAL STEPS: 579, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 1.809229478671213, ((4, 2), 'exit'): 9.999998929930953, ((2, 4), 'east'): 6.138062739985761, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.204307678910374, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.12740231308857347, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.54697471812299, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.096639907313396, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.129555614069571, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.191913460688459, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.0184995356113133, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 3.8698178719226144, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.99964406600365}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 67

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 67 COMPLETE: RETURN WAS 4.3046721

TOTAL STEPS: 588, EPISODE STEPS: 9
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 2.3113114604889553, ((4, 2), 'exit'): 9.999999250951667, ((2, 4), 'east'): 6.238460552375917, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.204307678910374, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.577673578403229, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.54697471812299, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.097551832940361, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.247965869644855, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 0.16673042962555687, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.220432197456539, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.0184995356113133, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 4.093852526144614, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.999750557283912}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 68

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 68 COMPLETE: RETURN WAS 4.3046721

TOTAL STEPS: 597, EPISODE STEPS: 9
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 2.3113114604889553, ((4, 2), 'exit'): 9.999999475666167, ((2, 4), 'east'): 6.316439079976408, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.204307678910374, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9802267325699998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 0.577673578403229, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.54697471812299, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.7738999999999998, ((3, 3), 'east'): 8.098218933524908, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.322439500050773, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.0, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.240641533113475, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.0184995356113133, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0, ((0, 4), 'east'): 4.093852526144614, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.999825187855688}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 69

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (1, 1), A: west, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (1, 1), A: north, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (0, 1), A: west, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (0, 1), A: west, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (2, 4), A: east, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (2, 3), A: east, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 13, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 69 COMPLETE: RETURN WAS 0.254186582833

TOTAL STEPS: 611, EPISODE STEPS: 14
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 2.7232582044013145, ((4, 2), 'exit'): 9.999999475666167, ((2, 4), 'east'): 6.096670429289286, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 4.607676593031162, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 5.852876566932981, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9861587127989999, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 1.0284255992142781, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.54697471812299, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 8.098218933524908, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.431146201629171, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.15597186616887185, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.240641533113475, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.0184995356113133, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.302755433314938, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.999825187855688}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 70

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (3, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 70 COMPLETE: RETURN WAS 3.1381059609

TOTAL STEPS: 623, EPISODE STEPS: 12
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 2.7232582044013145, ((4, 2), 'exit'): 9.999999632966317, ((2, 4), 'east'): 6.222642514443138, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 4.607676593031162, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 6.283664231483973, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9861587127989999, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.096538021665895, ((0, 2), 'north'): 1.0284255992142781, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 2.612551496835806, ((4, 4), 'west'): 5.841723712698505, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.928974211515007, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.447903357048527, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.15597186616887185, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.265128364292696, ((1, 4), 'south'): 0.6825495064331698, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.302755433314938, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.999877489928846}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 71

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (1, 4), A: north, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 71 COMPLETE: RETURN WAS 2.82429536481

TOTAL STEPS: 636, EPISODE STEPS: 13
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 3.0680247100759535, ((4, 2), 'exit'): 9.999999743076422, ((2, 4), 'east'): 6.317434418469224, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 4.607676593031162, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 6.283664231483973, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9861587127989999, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 1.4551776346383494, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 3.7799175286558278, ((4, 4), 'west'): 5.841723712698505, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.980248870341292, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.493645828833616, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.15597186616887185, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.199312061588809, ((1, 4), 'south'): 1.9487185609063213, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.482862709723559, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7304774382179997, ((4, 3), 'south'): 8.999914143851097}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 72

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 72 COMPLETE: RETURN WAS 0.9

TOTAL STEPS: 638, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 3.0680247100759535, ((4, 2), 'exit'): 9.999999743076422, ((2, 4), 'east'): 6.317434418469224, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 4.607676593031162, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 6.283664231483973, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9903110989592998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 1.4551776346383494, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 3.7799175286558278, ((4, 4), 'west'): 5.841723712698505, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.980248870341292, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.493645828833616, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.15597186616887185, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.199312061588809, ((1, 4), 'south'): 1.9487185609063213, ((4, 3), 'east'): 7.269032029280654, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.482862709723559, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7775970592083297, ((4, 3), 'south'): 8.999914143851097}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 73

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 3), A: south, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (4, 3), A: east, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 73 COMPLETE: RETURN WAS 6.561

TOTAL STEPS: 643, EPISODE STEPS: 5
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.0, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 3.0680247100759535, ((4, 2), 'exit'): 9.999999820153494, ((2, 4), 'east'): 6.317434418469224, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.380040810113962, ((0, 2), 'east'): 0.0, ((3, 3), 'south'): 6.283664231483973, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9903110989592998, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 1.4551776346383494, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 3.7799175286558278, ((4, 4), 'west'): 5.841723712698505, ((0, 3), 'east'): 0.0, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 8.016151028078701, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.493645828833616, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.15597186616887185, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.199312061588809, ((1, 4), 'south'): 1.9487185609063213, ((4, 3), 'east'): 7.788322351127091, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.482862709723559, ((1, 1), 'north'): 0.0, ((2, 1), 'north'): 0.7775970592083297, ((4, 3), 'south'): 8.729916719535563}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 74

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 2), A: east, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 3), A: east, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (0, 2), A: south, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (0, 1), A: east, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 1), A: north, S': (2, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 74 COMPLETE: RETURN WAS 0.4782969

TOTAL STEPS: 651, EPISODE STEPS: 8
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 3.0680247100759535, ((4, 2), 'exit'): 9.999999820153494, ((2, 4), 'east'): 6.317434418469224, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.380040810113962, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.283664231483973, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 1.846991015967352, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 3.7799175286558278, ((4, 4), 'west'): 5.841723712698505, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 8.016151028078701, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.493645828833616, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.15597186616887185, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.199312061588809, ((1, 4), 'south'): 1.9487185609063213, ((4, 3), 'east'): 7.788322351127091, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 0.0, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.482862709723559, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.729916719535563}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 75

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 3), A: south, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (4, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (3, 3), A: south, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (4, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 13, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 14, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 75 COMPLETE: RETURN WAS 2.2876792455

TOTAL STEPS: 666, EPISODE STEPS: 15
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 3.357990228678528, ((4, 2), 'exit'): 9.999999874107445, ((2, 4), 'east'): 6.366018349557435, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.380040810113962, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.3132489397488647, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 3.7799175286558278, ((4, 4), 'west'): 5.841723712698505, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.720357979926246, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.551259373170222, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.15597186616887185, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.203879220693415, ((1, 4), 'south'): 1.9487185609063213, ((4, 3), 'east'): 7.788322351127091, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 0.5727403033823664, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.621288270591568, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.254602919303752}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 76

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 3), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 76 COMPLETE: RETURN WAS 3.486784401

TOTAL STEPS: 677, EPISODE STEPS: 11
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 0.0, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 3.5278231983324435, ((4, 2), 'exit'): 9.99999991187521, ((2, 4), 'east'): 6.401260234277426, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.380040810113962, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 1.1242576935225275, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.525931619567408, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 3.7799175286558278, ((4, 4), 'west'): 5.841723712698505, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 1.2920358398471783, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.632993374160385, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.604706515599663, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.7337575200504037, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 7.127212109065477, ((1, 4), 'south'): 1.9487185609063213, ((4, 3), 'east'): 7.788322351127091, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 0.5727403033823664, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.7337418201700565, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.478222009521636}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 77

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 3), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (0, 3), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (0, 3), A: south, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (1, 4), A: south, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 13, S: (2, 4), A: south, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 14, S: (2, 3), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 15, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 16, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 17, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 18, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 19, S: (3, 3), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 20, S: (3, 4), A: south, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 21, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 22, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 23, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 24, S: (4, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 25, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 26, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 77 COMPLETE: RETURN WAS 0.646108188923

TOTAL STEPS: 704, EPISODE STEPS: 27
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 0.6820015372832002, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 0.0632043, ((0, 3), 'north'): 3.6016404845636125, ((4, 2), 'exit'): 9.999999938312648, ((2, 4), 'east'): 6.4052294334418765, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.494368830334677, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.8006838668468306, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 4.5494305756487465, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.632215304483111, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.533935987347075, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.7337575200504037, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.619472769534198, ((1, 4), 'south'): 3.3350269475791983, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.8466956597672155, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.63475538287145}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 78

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 4), A: east, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (2, 3), A: west, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 78 COMPLETE: RETURN WAS 5.31441

TOTAL STEPS: 711, EPISODE STEPS: 7
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 0.6820015372832002, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.6016404845636125, ((4, 2), 'exit'): 9.999999956818854, ((2, 4), 'east'): 5.967140187599676, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.906756313444713, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.8006838668468306, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 4.5494305756487465, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.513658145119323, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -6.569999999999999, ((1, 4), 'east'): 5.533935987347075, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.7337575200504037, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.619472769534198, ((1, 4), 'south'): 3.3350269475791983, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.87143496372912, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.8466956597672155, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.74432875135443}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 79

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (3, 1), A: east, S': (3, 0), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 1, S: (3, 0), A: exit, S': TERMINAL_STATE, R: -10

Current Policy Agreement Ratio: 0.600000
--------------------------------
EPISODE 79 COMPLETE: RETURN WAS -9.0

TOTAL STEPS: 713, EPISODE STEPS: 2
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 0.6820015372832002, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.6016404845636125, ((4, 2), 'exit'): 9.999999956818854, ((2, 4), 'east'): 5.967140187599676, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.906756313444713, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 0.0, ((3, 4), 'north'): 2.525054619874547, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.8006838668468306, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 4.5494305756487465, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.513658145119323, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.533935987347075, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.7337575200504037, ((2, 4), 'west'): 1.5633606243689715, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 2.5665864608571, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.619472769534198, ((1, 4), 'south'): 3.3350269475791983, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 0.23610447461038397, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.8466956597672155, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.74432875135443}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.600000
################################

BEGINNING EPISODE: 80

Current Policy Agreement Ratio: 0.600000
Step: 0, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 1, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 2, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 3, S: (3, 4), A: west, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 4, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 5, S: (1, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 6, S: (1, 4), A: south, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 7, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 8, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 9, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 10, S: (2, 4), A: west, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 11, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 12, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 13, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 14, S: (3, 3), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 15, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 16, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 17, S: (4, 3), A: south, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 18, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.600000
Step: 19, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.600000
--------------------------------
EPISODE 80 COMPLETE: RETURN WAS 1.35085171767

TOTAL STEPS: 733, EPISODE STEPS: 20
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 0.6820015372832002, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.6016404845636125, ((4, 2), 'exit'): 9.999999969773198, ((2, 4), 'east'): 5.962236693140039, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.906756313444713, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 3.5547958816864162, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.8006838668468306, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 4.5494305756487465, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.620529464449222, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.344558312369248, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 7.636756701691872, ((0, 1), 'north'): 0.7337575200504037, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.692310745681526, ((1, 4), 'south'): 3.986679552655885, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 0.23610447461038397, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.829177830483125, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.637399210510747}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Action 'north' at state (3, 1) is not optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.600000
################################

BEGINNING EPISODE: 81

Current Policy Agreement Ratio: 0.600000
Step: 0, S: (3, 1), A: east, S': (4, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (4, 1), A: north, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 81 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 736, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 0.6820015372832002, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.6016404845636125, ((4, 2), 'exit'): 9.999999978841238, ((2, 4), 'east'): 5.962236693140039, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.906756313444713, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 3.5547958816864162, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.8006838668468306, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 4.5494305756487465, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.620529464449222, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.344558312369248, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 0.7337575200504037, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.692310745681526, ((1, 4), 'south'): 3.986679552655885, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.829177830483125, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.637399210510747}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 82

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 82 COMPLETE: RETURN WAS 3.486784401

TOTAL STEPS: 747, EPISODE STEPS: 11
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.2335857201468845, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.8250263534249727, ((4, 2), 'exit'): 9.999999985188866, ((2, 4), 'east'): 5.980489586532039, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 5.906756313444713, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 3.5547958816864162, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.9329216376249567, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 4.5494305756487465, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.666468411952357, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.350994725806284, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.269814908083927, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.742160477378357, ((1, 4), 'south'): 3.986679552655885, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.823455225677884, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.746179441644657}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 83

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 83 COMPLETE: RETURN WAS 7.29

TOTAL STEPS: 751, EPISODE STEPS: 4
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.2335857201468845, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.8250263534249727, ((4, 2), 'exit'): 9.999999989632206, ((2, 4), 'east'): 5.980489586532039, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.204675890638436, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 3.5547958816864162, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.9329216376249567, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 4.5494305756487465, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.727996337610707, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.350994725806284, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.269814908083927, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.742160477378357, ((1, 4), 'south'): 3.986679552655885, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.823455225677884, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.822325605152253}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 84

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (3, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (3, 3), A: west, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (3, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 84 COMPLETE: RETURN WAS 4.782969

TOTAL STEPS: 759, EPISODE STEPS: 8
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.2335857201468845, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.8250263534249727, ((4, 2), 'exit'): 9.999999992742545, ((2, 4), 'east'): 6.006726039464584, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.204675890638436, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 2.9329216376249567, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.271160414109013, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.629337426628776, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.350994725806284, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.269814908083927, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.80607134531974, ((1, 4), 'south'): 3.986679552655885, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.823455225677884, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.875627920807272}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 85

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (0, 2), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 4), A: south, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 7, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 8, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 9, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 10, S: (4, 3), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 11, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 12, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 13, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.666667
--------------------------------
EPISODE 85 COMPLETE: RETURN WAS 2.54186582833

TOTAL STEPS: 773, EPISODE STEPS: 14
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.2335857201468845, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.9798513583305093, ((4, 2), 'exit'): 9.999999994919781, ((2, 4), 'east'): 6.042347490861538, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.204675890638436, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9932177692715098, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 3.024210907372088, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.271160414109013, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.657386766359364, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.367512338719837, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.6807592778174871, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.8241710469135874, ((1, 4), 'south'): 4.2354442628268165, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.821187233942216, ((1, 1), 'north'): 0.20995120598624903, ((2, 1), 'north'): 0.8117019381648416, ((4, 3), 'south'): 8.511342313577833}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Action 'north' at state (1, 1) is not optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.666667
################################

BEGINNING EPISODE: 86

Current Policy Agreement Ratio: 0.666667
Step: 0, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 1, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 2, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 3, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 4, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 5, S: (1, 1), A: north, S': (1, 1), R: 0.0

Current Policy Agreement Ratio: 0.666667
Step: 6, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 7, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 8, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.733333
--------------------------------
EPISODE 86 COMPLETE: RETURN WAS 0.43046721

TOTAL STEPS: 782, EPISODE STEPS: 9
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.2335857201468845, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.9798513583305093, ((4, 2), 'exit'): 9.999999994919781, ((2, 4), 'east'): 6.042347490861538, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.204675890638436, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9952524384900567, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 3.024210907372088, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.271160414109013, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.657386766359364, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.367512338719837, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.6807592778174871, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0.21915952330450722, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.8241710469135874, ((1, 4), 'south'): 4.2354442628268165, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.821187233942216, ((1, 1), 'north'): 0.17488347698762724, ((2, 1), 'north'): 0.8363601544186967, ((4, 3), 'south'): 8.511342313577833}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Policy at state (1, 1) is optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.733333
################################

BEGINNING EPISODE: 87

Current Policy Agreement Ratio: 0.733333
Step: 0, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 1, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 2, S: (4, 3), A: south, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 3, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 4, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.733333
--------------------------------
EPISODE 87 COMPLETE: RETURN WAS 6.561

TOTAL STEPS: 787, EPISODE STEPS: 5
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.2335857201468845, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 3.9798513583305093, ((4, 2), 'exit'): 9.999999996443847, ((2, 4), 'east'): 6.042347490861538, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.410767550363934, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9952524384900567, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 3.024210907372088, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.271160414109013, ((4, 4), 'west'): 5.8475100714574415, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -1.944, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.65823316111757, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.367512338719837, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.6807592778174871, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 1.1464062526146215, ((1, 1), 'east'): 0.21915952330450722, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.8241710469135874, ((1, 4), 'south'): 4.2354442628268165, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 3.610632848821127, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.821187233942216, ((1, 1), 'north'): 0.17488347698762724, ((2, 1), 'north'): 0.8363601544186967, ((4, 3), 'south'): 8.47920142954769}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Policy at state (1, 1) is optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.733333
################################

BEGINNING EPISODE: 88

Current Policy Agreement Ratio: 0.733333
Step: 0, S: (1, 1), A: south, S': (0, 1), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 1, S: (0, 1), A: north, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 2, S: (0, 2), A: west, S': (0, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 3, S: (0, 2), A: north, S': (0, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 4, S: (0, 3), A: north, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 5, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 6, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 7, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 8, S: (1, 4), A: west, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 9, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 10, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 11, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 12, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 13, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 14, S: (4, 3), A: north, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 15, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 16, S: (3, 4), A: south, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 17, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 18, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 19, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 20, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 21, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.733333
--------------------------------
EPISODE 88 COMPLETE: RETURN WAS 1.09418989132

TOTAL STEPS: 809, EPISODE STEPS: 22
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.680046949093283, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 1.5277225941903627, ((0, 3), 'north'): 4.087616503995754, ((4, 2), 'exit'): 9.999999997510692, ((2, 4), 'east'): 6.072169426269745, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.410767550363934, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 1.054174192788515, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9952524384900567, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 1.5224511857614114, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 3.1915075019096992, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.271160414109013, ((4, 4), 'west'): 5.885676411392868, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 3.5712760090584554, ((1, 1), 'south'): -0.9069949949892783, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.644487705109997, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.3886924596365, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.9930684394627047, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 2.7765251646646973, ((1, 1), 'east'): 0.21915952330450722, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.542322466710275, ((1, 4), 'south'): 4.2354442628268165, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 4.106270713468298, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.827477267127219, ((1, 1), 'north'): 0.17488347698762724, ((2, 1), 'north'): 0.8363601544186967, ((4, 3), 'south'): 8.63544099972322}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Policy at state (1, 1) is optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.733333
################################

BEGINNING EPISODE: 89

Current Policy Agreement Ratio: 0.733333
Step: 0, S: (2, 4), A: north, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 1, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 2, S: (3, 4), A: east, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 3, S: (4, 4), A: north, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 4, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 5, S: (3, 3), A: west, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 6, S: (2, 3), A: west, S': (2, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 7, S: (2, 3), A: east, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 8, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 9, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 10, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.733333
--------------------------------
EPISODE 89 COMPLETE: RETURN WAS 3.486784401

TOTAL STEPS: 820, EPISODE STEPS: 11
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.680046949093283, ((3, 1), 'west'): -0.81, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 2.800313054531516, ((0, 3), 'north'): 4.087616503995754, ((4, 2), 'exit'): 9.999999998257483, ((2, 4), 'east'): 6.0169456644005965, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.551548965634453, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 2.5043490009637353, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9952524384900567, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 2.6548484611090624, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 3.1915075019096992, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.420719528474571, ((4, 4), 'west'): 5.885676411392868, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 4.13937895143375, ((1, 1), 'south'): -0.9069949949892783, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.682710463502268, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.3886924596365, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.9930684394627047, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 2.7765251646646973, ((1, 1), 'east'): 0.21915952330450722, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.643637407076891, ((1, 4), 'south'): 4.2354442628268165, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 4.106270713468298, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.827477267127219, ((1, 1), 'north'): 0.17488347698762724, ((2, 1), 'north'): 0.8363601544186967, ((4, 3), 'south'): 8.744808699134142}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Policy at state (1, 1) is optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.733333
################################

BEGINNING EPISODE: 90

Current Policy Agreement Ratio: 0.733333
Step: 0, S: (3, 1), A: west, S': (2, 1), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 1, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 2, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.733333
--------------------------------
EPISODE 90 COMPLETE: RETURN WAS 0.81

TOTAL STEPS: 823, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.680046949093283, ((3, 1), 'west'): -0.3411827583069518, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 2.800313054531516, ((0, 3), 'north'): 4.087616503995754, ((4, 2), 'exit'): 9.999999998257483, ((2, 4), 'east'): 6.0169456644005965, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.551548965634453, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 2.5043490009637353, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9966767069430396, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 2.6548484611090624, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 3.1915075019096992, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.420719528474571, ((4, 4), 'west'): 5.885676411392868, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 4.13937895143375, ((1, 1), 'south'): -0.9069949949892783, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.682710463502268, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.3886924596365, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.9930684394627047, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 2.7765251646646973, ((1, 1), 'east'): 0.21915952330450722, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.643637407076891, ((1, 4), 'south'): 4.2354442628268165, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 4.106270713468298, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.827477267127219, ((1, 1), 'north'): 0.17488347698762724, ((2, 1), 'north'): 0.854170266485403, ((4, 3), 'south'): 8.744808699134142}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Policy at state (1, 1) is optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.733333
################################

BEGINNING EPISODE: 91

Current Policy Agreement Ratio: 0.733333
Step: 0, S: (1, 1), A: east, S': (2, 1), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 1, S: (2, 1), A: north, S': (2, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 2, S: (2, 2), A: exit, S': TERMINAL_STATE, R: 1

Current Policy Agreement Ratio: 0.733333
--------------------------------
EPISODE 91 COMPLETE: RETURN WAS 0.81

TOTAL STEPS: 826, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.680046949093283, ((3, 1), 'west'): -0.3411827583069518, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 2.800313054531516, ((0, 3), 'north'): 4.087616503995754, ((4, 2), 'exit'): 9.999999998257483, ((2, 4), 'east'): 6.0169456644005965, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.551548965634453, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 2.5043490009637353, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9976736948601277, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 2.6548484611090624, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 3.1915075019096992, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.420719528474571, ((4, 4), 'west'): 5.885676411392868, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 4.13937895143375, ((1, 1), 'south'): -0.9069949949892783, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.682710463502268, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.3886924596365, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.9930684394627047, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 2.7765251646646973, ((1, 1), 'east'): 0.38403763826421383, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.643637407076891, ((1, 4), 'south'): 4.2354442628268165, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 4.106270713468298, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.827477267127219, ((1, 1), 'north'): 0.17488347698762724, ((2, 1), 'north'): 0.8670218974144027, ((4, 3), 'south'): 8.744808699134142}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Policy at state (1, 1) is optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.733333
################################

BEGINNING EPISODE: 92

Current Policy Agreement Ratio: 0.733333
Step: 0, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 1, S: (4, 3), A: south, S': (4, 2), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 2, S: (4, 2), A: exit, S': TERMINAL_STATE, R: 10

Current Policy Agreement Ratio: 0.733333
--------------------------------
EPISODE 92 COMPLETE: RETURN WAS 8.1

TOTAL STEPS: 829, EPISODE STEPS: 3
Learned QValue: {((0, 1), 'east'): 0.0, ((4, 4), 'south'): 2.4103890275766378, ((0, 2), 'south'): 0.042112403865595394, ((0, 2), 'west'): 1.680046949093283, ((3, 1), 'west'): -0.3411827583069518, ((2, 0), 'exit'): 0, ((2, 1), 'east'): 0, ((4, 0), 'exit'): -3.0, ((2, 3), 'west'): 2.800313054531516, ((0, 3), 'north'): 4.087616503995754, ((4, 2), 'exit'): 9.999999998780238, ((2, 4), 'east'): 6.0169456644005965, ((0, 1), 'south'): -0.81, ((2, 3), 'east'): 6.551548965634453, ((0, 2), 'east'): 0.39289796135235433, ((3, 3), 'south'): 6.629414359784477, ((3, 3), 'north'): 1.7988260322211622, ((3, 4), 'north'): 4.3087404460726475, ((4, 4), 'north'): 2.5043490009637353, ((4, 1), 'south'): 0.0, ((2, 1), 'south'): 0, ((2, 2), 'exit'): 0.9976736948601277, ((0, 3), 'west'): 0.0, ((2, 4), 'south'): 2.239591404196539, ((4, 4), 'east'): 0, ((3, 4), 'east'): 2.6548484611090624, ((1, 4), 'north'): 2.9385105215692287, ((0, 2), 'north'): 3.1915075019096992, ((2, 3), 'north'): 1.240443306513096, ((3, 3), 'west'): 5.420719528474571, ((4, 4), 'west'): 5.885676411392868, ((0, 3), 'east'): 0.498687574311185, ((1, 0), 'exit'): -7.598999999999999, ((3, 1), 'south'): -1.377, ((2, 4), 'north'): 4.13937895143375, ((1, 1), 'south'): -0.9069949949892783, ((1, 1), 'west'): -1.2417299999999998, ((3, 3), 'east'): 7.738995673217806, ((0, 0), 'exit'): -5.1, ((2, 3), 'south'): 0.49655996999999996, ((3, 0), 'exit'): -7.598999999999999, ((1, 4), 'east'): 5.3886924596365, ((4, 3), 'west'): 5.592988739082605, ((4, 1), 'north'): 8.045729683023074, ((0, 1), 'north'): 1.9930684394627047, ((2, 4), 'west'): 3.2430274551882308, ((1, 4), 'west'): 2.7765251646646973, ((1, 1), 'east'): 0.38403763826421383, ((0, 4), 'north'): 0.0, ((2, 1), 'west'): 0, ((0, 4), 'south'): 0.0, ((3, 4), 'west'): 3.406959582955352, ((3, 1), 'north'): 1.4078298402914442, ((3, 4), 'south'): 6.643637407076891, ((1, 4), 'south'): 4.2354442628268165, ((4, 3), 'east'): 7.740945588359805, ((4, 1), 'west'): 0.0, ((0, 4), 'west'): 0.0, ((4, 3), 'north'): 4.106270713468298, ((0, 3), 'south'): 1.1354975996243315, ((3, 1), 'east'): 2.227197441684074, ((4, 1), 'east'): 0.0, ((0, 1), 'west'): 0.0, ((0, 4), 'east'): 4.827477267127219, ((1, 1), 'north'): 0.17488347698762724, ((2, 1), 'north'): 0.8670218974144027, ((4, 3), 'south'): 8.82136608892342}

--------------------------------

Action 'north' at state (0, 1) is not optimal
Action 'north' at state (0, 2) is not optimal
Policy at state (0, 3) is optimal
Policy at state (0, 4) is optimal
Policy at state (1, 1) is optimal
Policy at state (1, 4) is optimal
Action 'north' at state (2, 1) is not optimal
Policy at state (2, 3) is optimal
Policy at state (2, 4) is optimal
Policy at state (3, 1) is optimal
Policy at state (3, 3) is optimal
Policy at state (3, 4) is optimal
Policy at state (4, 1) is optimal
Policy at state (4, 3) is optimal
Action 'west' at state (4, 4) is not optimal
################################
Current Policy Convergence Ratio: 0.733333
################################

BEGINNING EPISODE: 93

Current Policy Agreement Ratio: 0.733333
Step: 0, S: (0, 4), A: east, S': (0, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 1, S: (0, 4), A: east, S': (1, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 2, S: (1, 4), A: east, S': (2, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 3, S: (2, 4), A: east, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 4, S: (3, 4), A: south, S': (4, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 5, S: (4, 4), A: west, S': (3, 4), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 6, S: (3, 4), A: south, S': (3, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Step: 7, S: (3, 3), A: east, S': (4, 3), R: 0.0

Current Policy Agreement Ratio: 0.733333
Traceback (most recent call last):
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/Users/lguan/env-tensorflow-py2.7/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/Users/lguan/Documents/Study/Research/Summer 2018/Week8/BerkeleyGridWorld/experiment/expr_launcher_terminal.py", line 167, in <module>
    run_experiments()
  File "/Users/lguan/Documents/Study/Research/Summer 2018/Week8/BerkeleyGridWorld/experiment/expr_launcher_terminal.py", line 161, in run_experiments
    , is_use_q_learning_agent=is_use_q_learning_agent)
  File "/Users/lguan/Documents/Study/Research/Summer 2018/Week8/BerkeleyGridWorld/experiment/expr_launcher_terminal.py", line 119, in run_expr
    experiment_stat = tamerGridWorld.run_episodes()
  File "BerkeleyGridWorld/gridworld.py", line 789, in run_episodes
    , optimal_policy=self.optimal_policy)
  File "BerkeleyGridWorld/gridworld.py", line 588, in runEpisode
    print("Current Policy Agreement Ratio: %f" % policy_convergence_ratio)
  File "BerkeleyGridWorld/experiment_creater_and_resumer/experiment_creater_and_resumer.py", line 34, in write
    def write(self, message):
KeyboardInterrupt
